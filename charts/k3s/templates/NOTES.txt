Your {{ .Chart.Name }} Helm chart for provisioning a {{ .Values.name | default .Release.Name }} K3s cluster has been deployed.

The actual cluster provisioning is managed by the FluxCD Terraform controller.

1. Check GitRepository source:
   kubectl get gitrepositories -n flux-system {{ .Release.Name }} -o wide

2. Check Terraform resource:
   kubectl get terraforms -n flux-system {{ .Release.Name }} -o wide
   kubectl describe terraforms -n flux-system {{ .Release.Name }}

   (Provisioning a K3s cluster can take some time, depending on VM creation and K3s setup.)

3. Important Reminders from your values.yaml:
   Ensure all 'TODO' items are correctly filled, especially:
   - 'k3s_version'.
   - VM provisioning details if your Terraform module creates VMs (e.g., instance types, image IDs, SSH user, VPC/subnet details).
   - Ensure the SSH private key is provided via the '{{ .Release.Name }}-k3s-ssh-key' Kubernetes secret or as required by your TF module.
   - Any specific K3s server/agent flags or token if not relying on TF module defaults.
   - Ensure cloud credentials for VM provisioning are in 'tf-cloud-creds' (or platform-specific) secret.

   Incorrect or missing values will likely cause Terraform provisioning to fail.

4. Cluster Outputs:
   Post-provisioning, outputs (like Kubeconfig, server IP) will be in the Secret:
   Name:      {{ .Release.Name }}-outputs
   Namespace: flux-system
   Inspect with: kubectl get secret -n flux-system {{ .Release.Name }}-outputs -o yaml

Thank you for using the {{ .Chart.Name }} chart!
